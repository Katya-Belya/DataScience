{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9dfbb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\ybelyayeva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "\n",
    "#for importing data and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e879b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data\n",
    "file_text = pd.read_csv('Documents/recognition_comment3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe568afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The txt file is opened and tokenized\n",
    "text_tokens = nltk.word_tokenize(' '.join(file_text['recognition'].astype(str).values))\n",
    "# Named-entity recognition\n",
    "corp_tag = nltk.pos_tag(text_tokens)\n",
    "corp_chunk = nltk.ne_chunk(corp_tag)\n",
    "proper = []\n",
    "for token in corp_chunk: \n",
    "    if hasattr(token, 'label') and token.label() == \"PERSON\":\n",
    "            proper.append(\" \".join(c[0] for c in token.leaves()))\n",
    "# Find the most common proper nouns \n",
    "# (in our case, only the first word was kept to eliminate duplicates \n",
    "# like first-name last-name, and last-name)           \n",
    "top_30 = Counter(proper).most_common(30)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4d2dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find similar words \n",
    "text = nltk.Text(text_tokens)\n",
    "all_words = {}\n",
    "context_index = nltk.text.ContextIndex(text_tokens)\n",
    "\n",
    "for word in text_tokens:\n",
    "    similar_words = context_index.similar_words(word)\n",
    "    all_words[word] = word\n",
    "    for similar_word in similar_words:\n",
    "        all_words[similar_word] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7d13281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-off: Time-off\n",
      "Agency/division: Agency/division\n",
      "wide: wide\n",
      "recognition: recognition\n",
      "event|Investment: event|Investment\n",
      "event|Time-off|Investment: event|Investment\n",
      "in: in\n",
      "my: my\n",
      "professional: professional\n",
      "development: development\n",
      "Shoutout: Shoutout\n",
      "Time-off|Investment: Shoutout\n",
      "Investment: Shoutout\n",
      "the: the\n",
      "Agency: Agency\n",
      "'s: 's\n",
      "newsletter|Time-off: newsletter|Time-off\n",
      "newsletter|Agency/division: newsletter|Agency/division\n",
      "event|Token: event|Token\n",
      "of: of\n",
      "appreciation|Time-off|Investment: appreciation|Time-off|Investment\n",
      "appreciation|Investment: appreciation|Time-off|Investment\n",
      "development|Having: development|Having\n",
      "senior: senior\n",
      "leadership: leadership\n",
      "recognize: recognize\n",
      "me: me\n",
      "newsletter|Investment: newsletter|Investment\n",
      "Other: Other\n",
      "Time-off|Other: Other\n",
      ":: :\n",
      "Promotion: Promotion\n",
      "appreciation|Time-off: appreciation|Time-off\n",
      "appreciation: appreciation|Time-off\n",
      "salary: appreciation|Time-off\n",
      "Token: Token\n",
      "Raise: Token\n",
      "appreciation|Having: appreciation|Having\n",
      "appreciation|Time-off|Having: appreciation|Having\n",
      "event|Having: event|Time-off|Having\n",
      "event|Time-off|Having: event|Time-off|Having\n",
      "newsletter|Token: newsletter|Token\n",
      "Monetary: Monetary\n",
      "increases: increases\n",
      "Merit: Merit\n",
      "bonus: bonus\n",
      "development|Other: development|Other\n",
      "more: more\n",
      "promotions: promotions\n",
      "I: I\n",
      "just: just\n",
      "love: love\n",
      "what: what\n",
      "i: i\n",
      "do: do\n",
      "here: here\n",
      "and: and\n",
      "DSI: DSI\n",
      "Financially: Financially\n",
      "with: with\n",
      "telework: telework\n",
      "a: a\n",
      "promotion: N/A\n",
      "N/A: N/A\n",
      "via: via\n",
      "grade: grade\n",
      "increase: increase\n",
      "is: is\n",
      "all: all\n",
      "that: that\n",
      "required: counterproductive\n",
      "counterproductive: counterproductive\n",
      ".: .\n",
      "Being: Being\n",
      "A: Being\n",
      "locked: locked\n",
      "into: into\n",
      "one: one\n",
      "for: for\n",
      "years: years\n",
      "makes: makes\n",
      "no: no\n",
      "sense: sense\n",
      "event|Time-off: event|Time-off\n",
      "event: event|Time-off\n",
      "Successful: Successful\n",
      "completion: completion\n",
      "Task: Task\n",
      "Continuous: Continuous\n",
      "Forward: Forward\n",
      "Progress: Progress\n",
      "on: on\n",
      "Project: Project\n",
      "Goals: Goals\n",
      "self-recognition: people\n",
      "work: people\n",
      "people: people\n",
      "require: need\n",
      "need: need\n",
      "n't: n't\n",
      "it: it\n",
      "as: as\n",
      "if: if\n",
      "am: am\n",
      "working: working\n",
      "doing: working\n",
      "God: God\n",
      "(: (\n",
      "bible: bible\n",
      "commands: commands\n",
      "to: to\n",
      "): )\n",
      "so: so\n",
      "because: because\n",
      "He: He\n",
      "knows: knows\n",
      "best: best\n",
      ",: ,\n",
      "Time-off|Having: Having\n",
      "Having: Having\n",
      "Assetts: Assetts\n",
      "customers: customers\n",
      "-: -\n",
      "better: better\n",
      "training: training\n",
      "providers: providers\n",
      "metro: metro\n",
      "fare: fare\n",
      "cards: cards\n",
      "swift: swift\n",
      "resolutions: resolutions\n",
      "UI: UI\n",
      "claims: claims\n",
      "event|Other: event|Other\n",
      "Money: N/A\n",
      "Pay: Pay\n",
      "raise: raise\n",
      "ability: ability\n",
      "remote: remote\n",
      "when: when\n",
      "needed: needed\n",
      "'m: 'm\n",
      "trusted: trusted\n",
      "job: job\n",
      "regardless: regardless\n",
      "location: location\n",
      "awards: awards\n",
      "certificates: certificates\n",
      "fair: fair\n",
      "equals: equals\n",
      "bonuses: bonuses\n",
      "services: services\n",
      "etc: etc\n",
      "appreciation|Other: appreciation|Other\n",
      "appreciation|Time-off|Other: appreciation|Other\n",
      "getting: getting\n",
      "together: together\n",
      "group: group\n",
      "be: be\n",
      "recognized: recognized\n",
      "whole: whole\n",
      "over: over\n",
      "dinner: dinner\n",
      "respectable: promoted\n",
      "promoted: promoted\n",
      "newsletter|Having: newsletter|Having\n",
      "Staff: Staff\n",
      "able: great\n",
      "great: great\n",
      "continue: continue\n",
      "help: help\n",
      "come: come\n",
      "through: through\n",
      "project: project\n",
      "empowerment: empowerment\n",
      "!: !\n",
      "$: $\n",
      "More: More\n",
      "flexibility: flexibility\n",
      "alternative: alternative\n",
      "When: When\n",
      "creative: creative\n",
      "intelligent: intelligent\n",
      "ideas: ideas\n",
      "are: are\n",
      "presented: presented\n",
      "would: would\n",
      "see: see\n",
      "them: them\n",
      "implimented: implimented\n",
      "Bonus: Bonus\n",
      "growth: growth\n"
     ]
    }
   ],
   "source": [
    "for word, similar_word in all_words.items():\n",
    "    print(f\"{word}: {similar_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c65b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
